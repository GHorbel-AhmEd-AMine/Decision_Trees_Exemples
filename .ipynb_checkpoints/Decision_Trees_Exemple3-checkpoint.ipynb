{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importer les modules n√©cessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>#Time.int</th>\n",
       "      <th>TT.lag1</th>\n",
       "      <th>TT.lag2</th>\n",
       "      <th>TT.lag3</th>\n",
       "      <th>TT.lag.delta1</th>\n",
       "      <th>TT.lag.delta2</th>\n",
       "      <th>Ax1</th>\n",
       "      <th>Ay1</th>\n",
       "      <th>Yaw 1</th>\n",
       "      <th>Ax2</th>\n",
       "      <th>Ay2</th>\n",
       "      <th>Yaw 2</th>\n",
       "      <th>Ax3</th>\n",
       "      <th>Ay3</th>\n",
       "      <th>Yaw 3</th>\n",
       "      <th>Travel_Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>37.431541</td>\n",
       "      <td>37.415785</td>\n",
       "      <td>37.400029</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>-0.022621</td>\n",
       "      <td>7.960968</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>-0.034859</td>\n",
       "      <td>3.944624</td>\n",
       "      <td>-0.089305</td>\n",
       "      <td>-0.047097</td>\n",
       "      <td>-0.071720</td>\n",
       "      <td>-0.100484</td>\n",
       "      <td>37.447297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>37.447297</td>\n",
       "      <td>37.431541</td>\n",
       "      <td>37.415785</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>11.977312</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>-0.022621</td>\n",
       "      <td>7.960968</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>-0.034859</td>\n",
       "      <td>3.944624</td>\n",
       "      <td>-0.089305</td>\n",
       "      <td>37.463053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>37.463053</td>\n",
       "      <td>37.447297</td>\n",
       "      <td>37.431541</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>15.993656</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>11.977312</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>-0.022621</td>\n",
       "      <td>7.960968</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>37.478808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>37.478808</td>\n",
       "      <td>37.463053</td>\n",
       "      <td>37.447297</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.044588</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>15.993656</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>11.977312</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>37.746841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>37.746841</td>\n",
       "      <td>37.478808</td>\n",
       "      <td>37.463053</td>\n",
       "      <td>0.268033</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.013224</td>\n",
       "      <td>17.780375</td>\n",
       "      <td>-0.048665</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.044588</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>15.993656</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>38.014874</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Day  #Time.int    TT.lag1    TT.lag2    TT.lag3  TT.lag.delta1  \\\n",
       "0    1         66  37.431541  37.415785  37.400029       0.015756   \n",
       "1    1         67  37.447297  37.431541  37.415785       0.015756   \n",
       "2    1         68  37.463053  37.447297  37.431541       0.015756   \n",
       "3    1         69  37.478808  37.463053  37.447297       0.015756   \n",
       "4    1         70  37.746841  37.478808  37.463053       0.268033   \n",
       "\n",
       "   TT.lag.delta2       Ax1        Ay1     Yaw 1       Ax2        Ay2  \\\n",
       "0       0.015756 -0.022621   7.960968 -0.078125 -0.034859   3.944624   \n",
       "1       0.015756 -0.010383  11.977312 -0.066946 -0.022621   7.960968   \n",
       "2       0.015756  0.001855  15.993656 -0.055767 -0.010383  11.977312   \n",
       "3       0.015756  0.014093  20.010000 -0.044588  0.001855  15.993656   \n",
       "4       0.015756  0.013224  17.780375 -0.048665  0.014093  20.010000   \n",
       "\n",
       "      Yaw 2       Ax3        Ay3     Yaw 3  Travel_Time  \n",
       "0 -0.089305 -0.047097  -0.071720 -0.100484    37.447297  \n",
       "1 -0.078125 -0.034859   3.944624 -0.089305    37.463053  \n",
       "2 -0.066946 -0.022621   7.960968 -0.078125    37.478808  \n",
       "3 -0.055767 -0.010383  11.977312 -0.066946    37.746841  \n",
       "4 -0.044588  0.001855  15.993656 -0.055767    38.014874  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importer la dataframe \n",
    "my_data= pd.read_excel(\"Segment.xlsx\")\n",
    "#Affichage des  premiers lignes \n",
    "my_data[0:5]\n",
    "# Ou bien \n",
    "my_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mise en place \"Decision tree\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=my_data['Travel_Time']\n",
    "X=my_data.drop(['Travel_Time'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       37.447297\n",
      "1       37.463053\n",
      "2       37.478808\n",
      "3       37.746841\n",
      "4       38.014874\n",
      "          ...    \n",
      "4129    37.499800\n",
      "4130    37.735015\n",
      "4131    37.970229\n",
      "4132    37.665634\n",
      "4133    37.361039\n",
      "Name: Travel_Time, Length: 4134, dtype: float64\n",
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "#Affichage du Serie y \n",
    "print(y)\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Day</th>\n",
       "      <th>#Time.int</th>\n",
       "      <th>TT.lag1</th>\n",
       "      <th>TT.lag2</th>\n",
       "      <th>TT.lag3</th>\n",
       "      <th>TT.lag.delta1</th>\n",
       "      <th>TT.lag.delta2</th>\n",
       "      <th>Ax1</th>\n",
       "      <th>Ay1</th>\n",
       "      <th>Yaw 1</th>\n",
       "      <th>Ax2</th>\n",
       "      <th>Ay2</th>\n",
       "      <th>Yaw 2</th>\n",
       "      <th>Ax3</th>\n",
       "      <th>Ay3</th>\n",
       "      <th>Yaw 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>66</td>\n",
       "      <td>37.431541</td>\n",
       "      <td>37.415785</td>\n",
       "      <td>37.400029</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>-0.022621</td>\n",
       "      <td>7.960968</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>-0.034859</td>\n",
       "      <td>3.944624</td>\n",
       "      <td>-0.089305</td>\n",
       "      <td>-0.047097</td>\n",
       "      <td>-0.071720</td>\n",
       "      <td>-0.100484</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>67</td>\n",
       "      <td>37.447297</td>\n",
       "      <td>37.431541</td>\n",
       "      <td>37.415785</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>11.977312</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>-0.022621</td>\n",
       "      <td>7.960968</td>\n",
       "      <td>-0.078125</td>\n",
       "      <td>-0.034859</td>\n",
       "      <td>3.944624</td>\n",
       "      <td>-0.089305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "      <td>37.463053</td>\n",
       "      <td>37.447297</td>\n",
       "      <td>37.431541</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>15.993656</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>11.977312</td>\n",
       "      <td>-0.066946</td>\n",
       "      <td>-0.022621</td>\n",
       "      <td>7.960968</td>\n",
       "      <td>-0.078125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>69</td>\n",
       "      <td>37.478808</td>\n",
       "      <td>37.463053</td>\n",
       "      <td>37.447297</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.044588</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>15.993656</td>\n",
       "      <td>-0.055767</td>\n",
       "      <td>-0.010383</td>\n",
       "      <td>11.977312</td>\n",
       "      <td>-0.066946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>70</td>\n",
       "      <td>37.746841</td>\n",
       "      <td>37.478808</td>\n",
       "      <td>37.463053</td>\n",
       "      <td>0.268033</td>\n",
       "      <td>0.015756</td>\n",
       "      <td>0.013224</td>\n",
       "      <td>17.780375</td>\n",
       "      <td>-0.048665</td>\n",
       "      <td>0.014093</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.044588</td>\n",
       "      <td>0.001855</td>\n",
       "      <td>15.993656</td>\n",
       "      <td>-0.055767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4129</td>\n",
       "      <td>2</td>\n",
       "      <td>235</td>\n",
       "      <td>37.264585</td>\n",
       "      <td>37.029371</td>\n",
       "      <td>36.794156</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.032088</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.057549</td>\n",
       "      <td>0.022209</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.055203</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4130</td>\n",
       "      <td>2</td>\n",
       "      <td>236</td>\n",
       "      <td>37.499800</td>\n",
       "      <td>37.264585</td>\n",
       "      <td>37.029371</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.037027</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.062240</td>\n",
       "      <td>0.032088</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.059894</td>\n",
       "      <td>0.027149</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.057549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4131</td>\n",
       "      <td>2</td>\n",
       "      <td>237</td>\n",
       "      <td>37.735015</td>\n",
       "      <td>37.499800</td>\n",
       "      <td>37.264585</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.041966</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.064586</td>\n",
       "      <td>0.037027</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.062240</td>\n",
       "      <td>0.032088</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.059894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4132</td>\n",
       "      <td>2</td>\n",
       "      <td>238</td>\n",
       "      <td>37.970229</td>\n",
       "      <td>37.735015</td>\n",
       "      <td>37.499800</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.046905</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.066931</td>\n",
       "      <td>0.041966</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.064586</td>\n",
       "      <td>0.037027</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.062240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4133</td>\n",
       "      <td>2</td>\n",
       "      <td>239</td>\n",
       "      <td>37.665634</td>\n",
       "      <td>37.970229</td>\n",
       "      <td>37.735015</td>\n",
       "      <td>-0.304595</td>\n",
       "      <td>0.235215</td>\n",
       "      <td>0.033690</td>\n",
       "      <td>17.997516</td>\n",
       "      <td>-0.077002</td>\n",
       "      <td>0.046905</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.066931</td>\n",
       "      <td>0.041966</td>\n",
       "      <td>20.010000</td>\n",
       "      <td>-0.064586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4134 rows √ó 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Day  #Time.int    TT.lag1    TT.lag2    TT.lag3  TT.lag.delta1  \\\n",
       "0       1         66  37.431541  37.415785  37.400029       0.015756   \n",
       "1       1         67  37.447297  37.431541  37.415785       0.015756   \n",
       "2       1         68  37.463053  37.447297  37.431541       0.015756   \n",
       "3       1         69  37.478808  37.463053  37.447297       0.015756   \n",
       "4       1         70  37.746841  37.478808  37.463053       0.268033   \n",
       "...   ...        ...        ...        ...        ...            ...   \n",
       "4129    2        235  37.264585  37.029371  36.794156       0.235215   \n",
       "4130    2        236  37.499800  37.264585  37.029371       0.235215   \n",
       "4131    2        237  37.735015  37.499800  37.264585       0.235215   \n",
       "4132    2        238  37.970229  37.735015  37.499800       0.235215   \n",
       "4133    2        239  37.665634  37.970229  37.735015      -0.304595   \n",
       "\n",
       "      TT.lag.delta2       Ax1        Ay1     Yaw 1       Ax2        Ay2  \\\n",
       "0          0.015756 -0.022621   7.960968 -0.078125 -0.034859   3.944624   \n",
       "1          0.015756 -0.010383  11.977312 -0.066946 -0.022621   7.960968   \n",
       "2          0.015756  0.001855  15.993656 -0.055767 -0.010383  11.977312   \n",
       "3          0.015756  0.014093  20.010000 -0.044588  0.001855  15.993656   \n",
       "4          0.015756  0.013224  17.780375 -0.048665  0.014093  20.010000   \n",
       "...             ...       ...        ...       ...       ...        ...   \n",
       "4129       0.235215  0.032088  20.010000 -0.059894  0.027149  20.010000   \n",
       "4130       0.235215  0.037027  20.010000 -0.062240  0.032088  20.010000   \n",
       "4131       0.235215  0.041966  20.010000 -0.064586  0.037027  20.010000   \n",
       "4132       0.235215  0.046905  20.010000 -0.066931  0.041966  20.010000   \n",
       "4133       0.235215  0.033690  17.997516 -0.077002  0.046905  20.010000   \n",
       "\n",
       "         Yaw 2       Ax3        Ay3     Yaw 3  \n",
       "0    -0.089305 -0.047097  -0.071720 -0.100484  \n",
       "1    -0.078125 -0.034859   3.944624 -0.089305  \n",
       "2    -0.066946 -0.022621   7.960968 -0.078125  \n",
       "3    -0.055767 -0.010383  11.977312 -0.066946  \n",
       "4    -0.044588  0.001855  15.993656 -0.055767  \n",
       "...        ...       ...        ...       ...  \n",
       "4129 -0.057549  0.022209  20.010000 -0.055203  \n",
       "4130 -0.059894  0.027149  20.010000 -0.057549  \n",
       "4131 -0.062240  0.032088  20.010000 -0.059894  \n",
       "4132 -0.064586  0.037027  20.010000 -0.062240  \n",
       "4133 -0.066931  0.041966  20.010000 -0.064586  \n",
       "\n",
       "[4134 rows x 16 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#affichage du data frame X \n",
    "print(type(X))\n",
    "X\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "Tree_model = DecisionTreeRegressor(random_state = 0, max_depth=5)\n",
    "Tree_model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.61233822]\n"
     ]
    }
   ],
   "source": [
    "#predict using the tree\n",
    "Prediction=Tree_model.predict([(1,72,38.2,38.0, 37.7, 0.26, 0.268, 0.011, 13.3, -0.05, 0.012,\n",
    "                               15.55, -0.052, 0.013, 17.78, -0.048)]) #This is numpy prediction array\n",
    "print (Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Autrement : \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4134, 17)\n",
      "(3307, 16)\n",
      "(3307,)\n",
      "(827, 16)\n",
      "(827,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split \n",
    "#On va divider la data frame en deux partie : une partie pour \"le training\" et l'autre pour \"le testing\" \n",
    "X_train,X_valid,y_train,y_valid=train_test_split(X,y,test_size=0.2,random_state=0)\n",
    "print(my_data.shape)\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_valid.shape)\n",
    "print(y_valid.shape)\n",
    "#On constate ici qu'on prend 70% du donn√©es pour faire \"le training\" des donn√©es et 30% pour faire \"le testing\"\n",
    "#et ceci se manifeste par la taille du X_train et y_train est et √©galement par la taille du X_valid et y_valid\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=5, max_features=None,\n",
       "                      max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "                      min_impurity_split=None, min_samples_leaf=1,\n",
       "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                      presort=False, random_state=0, splitter='best')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "Tree_model = DecisionTreeRegressor(random_state = 0, max_depth=5)\n",
    "Tree_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1281, 2859, 1910, 1113, 2850, 2896,  405, 1164, 2541, 2552, 1506,\n",
       "       2056,  222,  829, 1213, 1346,  884, 2031, 3231, 1828,  446, 2338,\n",
       "        585,  508, 2819, 3134, 2775, 1629,  845, 2655, 2859, 1408,  682,\n",
       "       2190, 1078, 1001, 2019,  695, 1992,  568, 2601, 1535, 1693,  921,\n",
       "       3016, 1978, 1597,  423, 2948, 2764,  995, 2355,  564, 1217, 1203,\n",
       "       2980,  224, 1940, 2952, 1140, 1904, 2875, 2245,  590,  950, 2977,\n",
       "       3297, 1655, 1978, 1980,  875, 2786, 1017,  862,  849, 1965, 2333,\n",
       "       3026, 1161,   91,  725, 2453, 1547,  268, 1534,  868, 2018, 1289,\n",
       "       2559, 1452,  915, 2906, 2314,  477, 2716, 1648, 3147,  224, 2793,\n",
       "       2448, 1447, 1772, 1716,  171, 2484, 1219, 1693, 2484,  220, 1338,\n",
       "       1992, 1324, 2174,  796, 2024, 3003,  349, 2621, 2102,  638,  719,\n",
       "       1540, 2244, 2627, 1687,  926, 2814, 2041, 1639,    8, 2573, 1324,\n",
       "       1741, 2110,  718, 1824,  380, 1034, 1522,  145,  743,  733,  451,\n",
       "        761, 1452, 1299, 2319, 2716, 1428, 3274,  276, 2812, 3004,  220,\n",
       "        706,  553, 2764, 3138, 2484, 3067,  165, 3136, 2364, 2231,  509,\n",
       "       2226, 2756, 2812, 2496,  586, 1350, 3231, 1093, 1378,   46, 2926,\n",
       "       1839,  622, 3042,  885,  976, 3063, 3019, 1511, 2609, 3153,  292,\n",
       "       2113, 1963,  775, 1699, 2852, 2395, 1345, 2201, 1423, 1244,  977,\n",
       "        657,  563, 2455,  653, 2764, 1061, 3077, 1661,  796,  500, 3183,\n",
       "       2038, 2411, 2203,  991, 2093, 2342,  662, 1921, 2315,  624, 2835,\n",
       "       2859, 1787, 1665, 2390, 1357,   38,  479,  786, 1188, 2575, 2134,\n",
       "        930,  381, 1587, 3093, 1887,  431,  838,  619, 2948,  171, 1011,\n",
       "       1853, 1142, 2211,    5,  988, 1532,  706,  251, 2543, 1240,  950,\n",
       "       2698,  910,  226,  646, 2700, 2506,  454, 2486,  410,  573, 1534,\n",
       "       1708, 3044, 2246, 2098, 3104, 2283,  653, 2601, 1518, 2393, 2939,\n",
       "       2267, 1417, 1720, 2320, 2110, 1019,  484, 1057, 1188, 3143,  978,\n",
       "       2577,   92, 1638,  676, 3267, 1434, 1142, 3157, 3089, 2216, 2505,\n",
       "       1197, 2356, 3285, 2642, 2484, 1380, 2031, 3163, 1071, 1057, 2606,\n",
       "       2886, 2681,  181, 1328, 1149,  574,  618, 2308,  820, 2297,  808,\n",
       "       3144, 2608, 2725, 2656,  847,  755, 2670, 3026, 2338,   26, 1976,\n",
       "       1352, 1352, 2722, 2740, 1428, 1865, 1707,  193, 1784,  796, 2957,\n",
       "        646, 2902,  292, 2014,  142, 2164, 1908, 2137,  523, 1338, 2958,\n",
       "        743, 1257, 3273, 2204, 3078, 1401,  858, 2448, 1031,  763,  796,\n",
       "       3124, 1242, 2374, 1452, 2599, 2541,  864, 3162, 3096, 1698, 1337,\n",
       "       3104, 2470, 1386, 3167, 2527, 3112, 1339, 2851, 2105,  334, 3210,\n",
       "        857, 2886, 1010, 1558, 1164, 2472,  511, 2876, 2541,  695, 1084,\n",
       "       1827, 1968, 2759, 2915, 2092, 1101, 1545,  559, 1633, 2649, 1214,\n",
       "       1666, 1214, 3131,  247, 1790, 2582, 2812, 2846, 2613,  828, 3115,\n",
       "       2379, 1714,  686,  863,  573,  171, 2882,  569, 1185,  648, 2374,\n",
       "       2317, 2985,  214, 2289,  246, 2416,  302, 1237,  127, 2256, 2867,\n",
       "       1675, 3077,  159, 3133,  217, 1007, 1503, 1610, 2882, 1678, 2790,\n",
       "       1630, 2684,  115,  377,  232, 1520, 2171,  680, 1264, 1204, 1886,\n",
       "       1417, 1322, 2407, 1887, 1852,  677,  980, 2705,    6,  667,  859,\n",
       "       1804, 1014, 2329, 3245, 2966,  926,  706, 1566, 2416, 1473, 2344,\n",
       "        428, 2508, 1882, 2688, 1607, 1835, 2816, 1237, 1176, 3135, 2564,\n",
       "       2853,   27, 1719, 1232,  187, 1312, 1781, 1217, 1716, 2851,  334,\n",
       "       1496, 2231,  529,  833,  199, 2648, 3074,  115,  404,  104, 2453,\n",
       "       2191, 2672,  813,  376,  581, 2533, 1682,  218, 2633,  657,  544,\n",
       "       1033, 2187, 2388, 2725, 2853, 2844,  476, 1395, 1228, 2474, 2963,\n",
       "        864,  501, 2355, 3147, 2267, 2416,  835, 3224, 2186, 2716, 1747,\n",
       "       2742, 2854,  517,  928, 1480,  300, 1101,   19,  132, 3216,  719,\n",
       "        553,  295,  409, 1116, 3061, 2506, 3149,  743, 2485, 3127, 2804,\n",
       "       1928, 1494, 1703, 1976, 2726, 2557,  696, 3066, 1696, 2518, 2964,\n",
       "        743, 3099,  737,  761, 1106, 2722, 2931, 1034, 1228,   18,  933,\n",
       "       3301, 1751, 1630,   32, 1266, 2987, 2632,  910, 1457, 1011, 2242,\n",
       "        444, 2552, 2745, 2270, 3269,  947, 1188, 3208,  149, 2012,  635,\n",
       "       2887, 1034,  261, 2905, 1388,  943, 2979,  234,  521,  749,  996,\n",
       "       2536, 1548, 2453,  229, 2231, 1064, 2654,  887, 1009, 2578, 1109,\n",
       "       2599, 2237, 2798, 1579, 2372, 1633, 1524,  214,  814,  892, 2752,\n",
       "       2169, 2314,  748, 2270, 2243, 1905,  766,  582,  464, 2765, 2195,\n",
       "       2756,  149, 1456, 1386, 1228,  988,  705, 1607, 2369, 1557,  214,\n",
       "        559, 2431, 2710, 2293, 2966, 1491, 1764, 1393,   70,  930, 1649,\n",
       "       3253, 1358, 3049,  283,  761, 2920, 2277,  864,  962,  446, 2568,\n",
       "       2859, 1264, 3035, 2719, 1177, 2886, 2832, 2189,  144, 2384, 1920,\n",
       "       2513, 2137, 3252, 3135, 2230, 1204,  877,  160, 3185,  326, 2260,\n",
       "       2677, 1231, 1002, 2500, 1427, 2346, 2466, 2409, 2815, 1102,  669,\n",
       "       1451, 1922, 2318,  426,  743, 3034, 2944,  100,  107, 1699, 2993,\n",
       "       2615, 1772,  666, 2623,   51,  586, 1352, 2514,  160, 1326, 1691,\n",
       "       1143, 2127, 1728, 1272,  323,  832, 1883, 1831, 1697,  171, 1535,\n",
       "        229, 2354,  143,  647, 1019, 1843, 1805, 2308, 1976, 3300, 1628,\n",
       "        426, 2718,  894, 2811, 1303, 3200, 2875, 1208, 2486,  905,  786,\n",
       "       1012, 1983, 1685, 1050, 1605, 2455,  727,  669, 1964, 1185, 1558,\n",
       "       2596, 1223, 2907,  864, 2315, 2008, 1228,   62, 1781, 2507,  472,\n",
       "       1412,  857,  458, 2374, 2016, 1454,  377, 2768, 3078,  591, 1360,\n",
       "       2367,  964, 2324, 1062, 2191, 3135, 2605,  321, 1639, 2718, 2942,\n",
       "       2370, 1284], dtype=int64)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction=Model.predict(X_valid)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pr√©cision du model :  0.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(\"La pr√©cision du model : \", metrics.accuracy_score(y_valid.round(), prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construire le model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "#cr√©er une instance du DecisionTreeClassifier\n",
    "Model = DecisionTreeClassifier() # on a fixer le max_depth √† 4 pour √©viter\n",
    "#les ph√©nom√®nes de underfitting et overfitting. \n",
    "Model # Affichage des param√©tres de default de ce model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn                        import metrics, svm\n",
    "from sklearn.linear_model           import LogisticRegression\n",
    "from sklearn import preprocessing\n",
    "from sklearn import utils\n",
    "lab_enc = preprocessing.LabelEncoder()\n",
    "training_scores_encoded = lab_enc.fit_transform(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "                       max_features=None, max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, presort=False,\n",
       "                       random_state=None, splitter='best')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Etape de training\n",
    "Model.fit(X_train,training_scores_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Etape de predicting \n",
    "prediction=Model.predict(X_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_scores = lab_enc.fit_transform(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La pr√©cision du model :  0.0012091898428053204\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "print(\"La pr√©cision du model : \", metrics.accuracy_score(training_scores, prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
